{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import load\n",
    "from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab, Doc\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "vectorizer_1st = load('1st_level/tfidf_vectorizer_1st_level.joblib')\n",
    "model_1st = load('1st_level/stacking_model_1st_level.joblib')\n",
    "label_encoder_1st = load('1st_level/label_encoder_1st_level.joblib')\n",
    "\n",
    "vectorizer_2nd = load('2nd_level/tfidf_vectorizer_2nd_level.joblib')\n",
    "model_2nd = load('2nd_level/random_forest_model_2nd_level.joblib')\n",
    "label_encoder_2nd = load('2nd_level/label_encoder_2nd_level.joblib')\n",
    "\n",
    "vectorizer_3rd = load('3rd_level/tfidf_vectorizer_3rd_level.joblib')\n",
    "model_3rd = load('3rd_level/stacking_model_3rd_level.joblib')\n",
    "label_encoder_3rd = load('3rd_level/label_encoder_3rd_level.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.1.0\n",
      "accelerate==0.33.0\n",
      "ace_tools==0.0\n",
      "annotated-types==0.6.0\n",
      "appnope==0.1.4\n",
      "art==6.2\n",
      "asgiref==3.8.1\n",
      "asttokens==2.4.1\n",
      "astunparse==1.6.3\n",
      "attrs==24.1.0\n",
      "blinker==1.7.0\n",
      "blis==0.7.11\n",
      "catalogue==2.0.10\n",
      "catboost==1.2.5\n",
      "certifi==2024.2.2\n",
      "charset-normalizer==3.3.2\n",
      "click==8.1.7\n",
      "cloudpathlib==0.16.0\n",
      "comm==0.2.2\n",
      "confection==0.1.4\n",
      "contourpy==1.2.0\n",
      "cv==1.0.0\n",
      "cycler==0.12.1\n",
      "cymem==2.0.8\n",
      "DAWG-Python==0.7.2\n",
      "debugpy==1.8.1\n",
      "decorator==4.4.2\n",
      "Django==5.0.4\n",
      "dm-tree==0.1.8\n",
      "docopt==0.6.2\n",
      "eli5==0.13.0\n",
      "et-xmlfile==1.1.0\n",
      "executing==2.0.1\n",
      "ffmpeg==1.4\n",
      "filelock==3.13.1\n",
      "Flask==3.0.3\n",
      "flatbuffers==23.5.26\n",
      "fonttools==4.49.0\n",
      "fsspec==2024.2.0\n",
      "gast==0.5.4\n",
      "google-pasta==0.2.0\n",
      "graphviz==0.20.1\n",
      "grpcio==1.62.0\n",
      "h5py==3.10.0\n",
      "huggingface-hub==0.21.4\n",
      "idna==3.6\n",
      "image==1.5.33\n",
      "imageio==2.34.0\n",
      "imageio-ffmpeg==0.4.9\n",
      "imbalanced-learn==0.12.3\n",
      "imblearn==0.0\n",
      "install==1.3.5\n",
      "intervaltree==3.1.0\n",
      "ipykernel==6.29.4\n",
      "ipymarkup==0.9.0\n",
      "ipython==8.24.0\n",
      "itsdangerous==2.1.2\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.3\n",
      "joblib==1.3.2\n",
      "jupyter_client==8.6.1\n",
      "jupyter_core==5.7.2\n",
      "keras==3.0.5\n",
      "keras-models==0.0.7\n",
      "kiwisolver==1.4.5\n",
      "langcodes==3.3.0\n",
      "lazy_loader==0.4\n",
      "libclang==16.0.6\n",
      "lime==0.2.0.1\n",
      "Markdown==3.5.2\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==2.1.5\n",
      "matplotlib==3.8.3\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "ml-dtypes==0.3.2\n",
      "moviepy==1.0.3\n",
      "mpmath==1.3.0\n",
      "murmurhash==1.0.10\n",
      "namex==0.0.7\n",
      "natasha==1.6.0\n",
      "navec==0.10.0\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.2.1\n",
      "nltk==3.8.1\n",
      "numpy==1.26.4\n",
      "opencv-python==4.9.0.80\n",
      "openpyxl==3.1.5\n",
      "opt-einsum==3.3.0\n",
      "packaging==23.2\n",
      "pandas==2.2.2\n",
      "parso==0.8.4\n",
      "pathlib==1.0.1\n",
      "patsy==0.5.6\n",
      "pexpect==4.9.0\n",
      "pillow==10.2.0\n",
      "platformdirs==4.2.1\n",
      "plotly==5.19.0\n",
      "preshed==3.0.9\n",
      "proglog==0.1.10\n",
      "prompt-toolkit==3.0.43\n",
      "protobuf==4.25.3\n",
      "psutil==5.9.8\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "pydantic==2.7.0\n",
      "pydantic_core==2.18.1\n",
      "Pygments==2.17.2\n",
      "pymorphy2==0.9.1\n",
      "pymorphy2-dicts-ru==2.4.417127.4579844\n",
      "pyparsing==3.1.1\n",
      "python-dateutil==2.8.2\n",
      "PythonTurtle==0.3.2\n",
      "pytz==2024.1\n",
      "PyWavelets==1.5.0\n",
      "PyYAML==6.0.1\n",
      "pyzmq==26.0.3\n",
      "razdel==0.5.0\n",
      "regex==2023.12.25\n",
      "requests==2.31.0\n",
      "rich==13.7.0\n",
      "safetensors==0.4.2\n",
      "scikit-image==0.24.0\n",
      "scikit-learn==1.5.1\n",
      "scipy==1.14.0\n",
      "seaborn==0.13.2\n",
      "setuptools==69.1.1\n",
      "six==1.16.0\n",
      "slovnet==0.6.0\n",
      "smart-open==6.4.0\n",
      "sortedcontainers==2.4.0\n",
      "spacy==3.7.5\n",
      "spacy-legacy==3.0.12\n",
      "spacy-loggers==1.0.5\n",
      "SpeechRecognition==3.10.1\n",
      "sqlparse==0.5.0\n",
      "srsly==2.4.8\n",
      "stack-data==0.6.3\n",
      "statsmodels==0.14.1\n",
      "sympy==1.12\n",
      "tabulate==0.9.0\n",
      "tenacity==8.2.3\n",
      "tensorboard==2.16.2\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.16.1\n",
      "termcolor==2.4.0\n",
      "textblob==0.18.0.post0\n",
      "thinc==8.2.3\n",
      "threadpoolctl==3.3.0\n",
      "tifffile==2024.7.24\n",
      "tokenizers==0.15.2\n",
      "torch==2.2.1\n",
      "torchvision==0.17.1\n",
      "tornado==6.4\n",
      "tqdm==4.66.2\n",
      "traitlets==5.14.3\n",
      "transformers==4.38.2\n",
      "typer==0.9.4\n",
      "typing_extensions==4.10.0\n",
      "tzdata==2024.1\n",
      "urllib3==2.2.1\n",
      "vc==2018.7.10\n",
      "video-to-text-vtt==0.1.0\n",
      "videoTotext==1.0\n",
      "wasabi==1.1.2\n",
      "wcwidth==0.2.13\n",
      "weasel==0.3.4\n",
      "Werkzeug==3.0.1\n",
      "wheel==0.42.0\n",
      "wrapt==1.16.0\n",
      "xgboost==2.0.3\n",
      "yargy==0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', ' ', text)  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    text = text.lower()  \n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  \n",
    "    return text\n",
    "\n",
    "segmenter = Segmenter()\n",
    "embedding = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(embedding)\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    return ' '.join([token.lemma for token in doc.tokens])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    clean = clean_text(text)\n",
    "    lemmatized = lemmatize_text(clean)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tags(text):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    X_1st_level = vectorizer_1st.transform([preprocessed_text])\n",
    "    pred_1st_level = model_1st.predict(X_1st_level)\n",
    "    tag_1st_level = label_encoder_1st.inverse_transform(pred_1st_level)[0]\n",
    "    \n",
    "    text_for_2nd = preprocessed_text + \" \" + tag_1st_level\n",
    "    \n",
    "    X_2nd_level = vectorizer_2nd.transform([text_for_2nd])\n",
    "    pred_2nd_level = model_2nd.predict(X_2nd_level)\n",
    "    tag_2nd_level = label_encoder_2nd.inverse_transform(pred_2nd_level)[0]\n",
    "    \n",
    "    text_for_3rd = text_for_2nd + \" \" + tag_2nd_level\n",
    "    \n",
    "    X_3rd_level = vectorizer_3rd.transform([text_for_3rd])\n",
    "    pred_3rd_level = model_3rd.predict(X_3rd_level)\n",
    "    tag_3rd_level = label_encoder_3rd.inverse_transform(pred_3rd_level)[0]\n",
    "    \n",
    "    return {\n",
    "        \"1st Level Tag\": tag_1st_level,\n",
    "        \"2nd Level Tag\": tag_2nd_level,\n",
    "        \"3rd Level Tag\": tag_3rd_level\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказанные теги для введённого текста:\n",
      "{'1st Level Tag': 'ОТСУТСТВУЕТ', '2nd Level Tag': 'Воспроизведение видео', '3rd Level Tag': 'Тормозит\\\\Лагает\\\\Зависает'}\n"
     ]
    }
   ],
   "source": [
    "example_text = \"Дно, 6 минутный ролик смотрел минут 15 в качестве 480. Оператор МТС. Ютуб летает в качестве 720, а это ГГ есть желание удалить\"\n",
    "predicted_tags = predict_tags(example_text)\n",
    "print(\"Предсказанные теги для введённого текста:\")\n",
    "print(predicted_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
